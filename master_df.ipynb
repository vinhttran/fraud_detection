{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load helper_functions2.py\n",
    "\n",
    "def user_event_count():\n",
    "    df['user_event_count'] = df.groupby('user_created').count().max(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def previous_payouts(df):\n",
    "    new_df=pd.DataFrame(df.previous_payouts[0])\n",
    "    for i in range(1,df.previous_payouts.shape[0]):\n",
    "        df_element=pd.DataFrame(df.previous_payouts[i])\n",
    "        new_df=pd.concat([new_df, df_element])\n",
    "    return new_df\n",
    "\n",
    "def user_df():\n",
    "    unique_cols = []\n",
    "    for col in columns:\n",
    "        if unique_col_indicator(df,col):\n",
    "            unique_cols.append(col)\n",
    "    user_unique_events = df.groupby('user_created').count().max(axis=1)\n",
    "    user_unique_events = pd.DataFrame(user_unique_events,columns=['user_event_count'])\n",
    "    return df[unique_cols].merge(user_unique_events,how='inner',on='user_created')\n",
    "\n",
    "def unique_col_indicator(df,col):\n",
    "    try:\n",
    "        col_count = df.groupby(['user_created',col])['channels'].count().shape[0]\n",
    "        user_count = df.groupby(['user_created'])['channels'].count().shape[0]\n",
    "        if col_count == user_count:\n",
    "            return True\n",
    "        else:\n",
    "\n",
    "            return False\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "#check\n",
    "def user_unique_events_col():\n",
    "    user_unique_events = df.groupby('user_created').count().max(axis=1)\n",
    "    user_unique_events =  pd.DataFrame(user_unique_events,columns=['user_event_count'])\n",
    "    return df.merge(user_unique_events,how='inner',on='user_created')\n",
    "\n",
    "#check\n",
    "def create_target():\n",
    "    df['fraud'] = df['acct_type'].map({'fraudster_event': 1,\n",
    "                                   'premium': 0,\n",
    "                                   'spammer_warn': 0,\n",
    "                                   'fraudster': 1,\n",
    "                                   'spammer_limited': 0,\n",
    "                                   'spammer_noinvite': 0,\n",
    "                                   'locked': 1,\n",
    "                                   'tos_lock': 0,\n",
    "                                   'tos_warn': 0,\n",
    "                                   'fraudster_att': 1,\n",
    "                                   'spammer_web': 0,\n",
    "                                   'spammer': 0})\n",
    "    return df\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#check\n",
    "def convert_date():\n",
    "    df[\"approx_payout_date\"] = pd.to_datetime(df[\"approx_payout_date\"], unit = 's')\n",
    "    df[\"event_created\"] = pd.to_datetime(df[\"event_created\"], unit = 's')\n",
    "    df[\"event_end\"] = pd.to_datetime(df[\"event_end\"], unit = 's')\n",
    "    df[\"event_start\"] = pd.to_datetime(df[\"event_start\"], unit = 's')\n",
    "    df[\"event_published\"] = pd.to_datetime(df[\"event_published\"], unit = 's')\n",
    "    return df\n",
    "\n",
    "def low_cor_cols(r_score):\n",
    "    df[num_cols()].corr()[['fraud']].values\n",
    "    corr_df = df[num_cols()].corr()[['fraud']].sort_values('fraud')\n",
    "    low_corr_mask = corr_df.sort_values('fraud').abs().lt(r_score).values.reshape(1,-1)[0]\n",
    "    return corr_df[low_corr_mask]\n",
    "\n",
    "def get_corrs():\n",
    "    corr_df = df[num_cols()].corr()[['fraud']].abs().sort_values('fraud')\n",
    "    return corr_df\n",
    "\n",
    "def num_cols():\n",
    "    return df.describe().columns\n",
    "\n",
    "def drop_cols():\n",
    "    df1 = df.drop(low_cor_cols(.09).index.tolist(),axis=1)\n",
    "    df2 = df1.drop(['acct_type','sale_duration','fraud','event_start','approx_payout_date',\n",
    "                    'event_published','event_end','venue_state',\n",
    "                    'ticket_types','venue_name','venue_state','venue_country','venue_address',\n",
    "                    'org_desc','org_name','previous_payouts','email_domain','name','currency','country','event_created'],axis=1)\n",
    "    return df2\n",
    "\n",
    "#check\n",
    "def description_cols():\n",
    "    import clean_desc\n",
    "    df['description'] = df['description'].apply(strip_tags)\n",
    "    clean_desc(df)\n",
    "    return df\n",
    "\n",
    "#check\n",
    "def ticket_types(df):\n",
    "    new_df=pd.DataFrame(df.ticket_types[0])\n",
    "    result_df=new_df[['quantity_sold', 'quantity_total', 'event_id']].groupby('event_id').sum()\n",
    "    result_df=result_df.join(new_df[['availability', 'cost', 'event_id']].groupby('event_id').mean())\n",
    "\n",
    "    for i in range(1,df.shape[0]):\n",
    "        try:\n",
    "            df_element=pd.DataFrame(df.ticket_types[i])\n",
    "            grp_ele_df=df_element[['quantity_sold', 'quantity_total', 'event_id']].groupby('event_id').sum()\n",
    "            grp_ele_df=grp_ele_df.join(df_element[['availability', 'cost', 'event_id']].groupby('event_id').mean())\n",
    "            result_df=pd.concat([result_df, grp_ele_df])\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    result_df.reset_index(inplace=True)\n",
    "    result_df.columns=['object_id', 'quantity_sold', 'quantity_total', 'availability', 'cost']\n",
    "    final_df=df.set_index('object_id').join(result_df.set_index('object_id'))\n",
    "    final_df.reset_index(inplace=True)\n",
    "    final_df[['quantity_sold', 'quantity_total','availability', 'cost']]=final_df[['quantity_sold', 'quantity_total','availability', 'cost']].fillna(0)\n",
    "    return final_df\n",
    "\n",
    "def timedelta(field):\n",
    "    return field.days\n",
    "\n",
    "def event_times():\n",
    "    df['publish_time_to_start'] =  df['event_published'] - df['event_created'] \n",
    "    df['publish_time_to_start'] = df['publish_time_to_start'].apply(timedelta)\n",
    "    return df\n",
    "\n",
    "def has_venue_data():\n",
    "    df['has_state'] = (df['venue_state'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    df['has_country'] = (df['venue_country'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    df['has_address'] = (df['venue_address'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    df['has_venue_name'] = (df['venue_name'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    \n",
    "    df['has_org_desc'] = (df['org_desc'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    df['has_org_name'] = (df['org_name'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    df['has_venue_name'] = (df['venue_name'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    df['has_venue_name'] = (df['venue_name'].fillna('None').replace('','None') == 'None').astype(int)\n",
    "    return df\n",
    "\n",
    "def payout_type():\n",
    "    df1 = pd.get_dummies(df,columns = ['payout_type','listed'])\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "pd.set_option('max_colwidth', 40)\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "sws = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "from  helper_functions import user_event_count,\\\n",
    "                                ticket_types,\\\n",
    "                                previous_payouts,\\\n",
    "                                user_df,\\\n",
    "                                unique_col_indicator,\\\n",
    "                                create_target,\\\n",
    "                                convert_date,\\\n",
    "                                low_cor_cols,\\\n",
    "                                drop_cols,\\\n",
    "                                description_cols,\\\n",
    "                                ticket_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/data.json').drop('description',axis=1)\n",
    "df = ticket_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_date()\n",
    "df = create_target()\n",
    "df = user_unique_events_col()\n",
    "df = event_times()\n",
    "df = has_venue_data()\n",
    "df = payout_type()\n",
    "df = drop_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14337 entries, 0 to 14336\n",
      "Data columns (total 22 columns):\n",
      "body_length          14337 non-null int64\n",
      "channels             14337 non-null int64\n",
      "delivery_method      14321 non-null float64\n",
      "fb_published         14337 non-null int64\n",
      "has_logo             14337 non-null int64\n",
      "name_length          14337 non-null int64\n",
      "org_facebook         14278 non-null float64\n",
      "org_twitter          14278 non-null float64\n",
      "payee_name           14337 non-null object\n",
      "sale_duration2       14337 non-null int64\n",
      "user_age             14337 non-null int64\n",
      "user_created         14337 non-null int64\n",
      "user_type            14337 non-null int64\n",
      "availability         14337 non-null float64\n",
      "has_state            14337 non-null int64\n",
      "has_country          14337 non-null int64\n",
      "has_address          14337 non-null int64\n",
      "has_venue_name       14337 non-null int64\n",
      "has_org_desc         14337 non-null int64\n",
      "has_org_name         14337 non-null int64\n",
      "payout_type_         14337 non-null uint8\n",
      "payout_type_CHECK    14337 non-null uint8\n",
      "dtypes: float64(4), int64(15), object(1), uint8(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
